% Discuss information explosion, the growing publication rate and easier data availability (Open access?)

The majority of scientific knowledge is delivered by scientific publications, research and experimentation. 
The growth rate of scientific publications has been steadily increasing over the years. 
The annual growth rate of publication output has increased in recent years, with a rate of 5\% over the last 4 years (2017 to 2020) and 4\% over the longer 11-year period (2010 to 2020)~\cite{publication_output_us}.
The growth in science is driven by the publication of novel ideas and experiments, most usually in peer-reviewed journals. 

% The worldwide growth rate for scientific publication was reported to be 3.7\% per year in the period 1981â€“1994~\cite{bornmann2021growth}. In life science, it amounts to 5.07\% with a doubling time of 14.0 years~\cite{mongeon2016journal}. 

% What is good about having a large quantity of data? 
The availability of a large quantity of data can open new opportunities and benefits. 
Firstly, it allows for more comprehensive and robust analyses, leading to more accurate and reliable results [ref]. 
Large datasets enable researchers to identify patterns, trends, and correlations that may not be apparent in smaller datasets [ref] and this can accelerate discovering.
This can lead to new insights and discoveries in various fields, including medicine, environmental science, and social sciences [ref]. Additionally, large datasets can be used to train and develop machine learning algorithms, which can automate processes, make predictions, and improve decision-making [ref].
In recent years we assisted in the so-called "big data era" in which the focus of private and academia was to define, build and administer proper infrastructures for collecting and managing such large datasets. 

% Why is hard to manage a large quantity of data? 

% e.g. Impossible to keep up with all the articles 
% e.g. It's difficult to find information that is pertinent to the context (Examples:  information about German Army in WW1 (imperial army) or WW2 (Wehrmacht)
% e.g. structured information cannot be extracted manually (ref to point 1)

On the other hand, having to manage large quantities of data poses several challenges. 
Firstly, it is becoming more difficult for researchers to keep up with the sheer volume of scientific articles being published leading to concerns about the quality and impact of researchers~\cite{rawat2014publish}.  
Secondly, finding specific detailed information can be overwhelming, especially in domains where the terminology is very precise and not well-known outside the domain.
While the full text represents the main container of information in scientific articles, the relevant findings might be summarised in tables or figures. 
For example, in certain sub-fields of computer science, the evaluation scores are summarised in tables, while in other domains like materials science, superconductor research summarise their finding in plots. 

% What is a language? 
In this dissertation, we focus on text written in the English language, which represents on average, more than 80\% of the total publications. 
A language is a structured system of communication that enables the exchange of information and ideas among individuals or groups. 
It is a complex and abstract system of symbols, sounds, and rules that allows people to convey meaning and convey thoughts, emotions, and information to others. 
Languages can take various forms, including spoken languages, sign languages, written languages, and even programming languages.
Key characteristics of language include vocabulary. A language consists of a set of words or signs that represent specific concepts or objects. 
These words are used to convey meaning.
The interaction between vocab is determined by rules for how words can be combined to create meaningful sentences. 
Grammar includes syntax (word order), morphology (word structure and inflexion), and semantics (meaning).
Languages are dynamic and constantly evolving over time, they can develop regional variations and dialects, or be incorporated into new words and expressions to reflect changes in society, technology, and culture. 

% difference between general language and scientific language 
Context plays an important role in how language is used, which type of terminology is used and how the expressions are constructed. There are many language styles, thus we can name two of the most relevant for this work: scientific and general language.
Scientific language, often referred to as technical or specialised language, is a form of language used primarily in the scientific, technical, and academic communities to communicate information, ideas, and findings related to specific fields of study. 
While scientific language is crucial for precise communication within the scientific community, it can be a barrier to understanding for individuals outside those fields. This is where general language comes into play, as it aims to make information accessible to a broader audience, including the general public. General language is less technical, uses everyday vocabulary, and is designed for clarity and ease of comprehension.

% Languages can be expressed by two main ways of communication: spoken and written. 
% The relationship between them is complex and multifaceted. 
% They are two distinct but interrelated modes of communication, and they serve different purposes while sharing many common elements. 
% In this dissertation, we focus exclusively on the written language. 

% Written language refers to the use of a visual representation of language through symbols, characters, or script on a surface, such as paper, screens, or other materials. 
% It is a system of communication that relies on the written word rather than spoken words to convey information, ideas, and messages.


% Why do we need machines to understand the text? 
The evolution of technology, marked by the digitisation process, commonly referred to as de-materialisation, has initiated a profound transformation in our daily lives. One notable aspect of this transformation is the increasing necessity for machines to comprehend written text. This need stems from the vast shift towards digital platforms, impacting various facets of our everyday experiences. 
As we explore the implications of this technological shift, the ability of machines to understand written text emerges as a pivotal component in navigating and enhancing our digitally-driven world.
Within this digital landscape, the demand for machines to comprehend written text has given rise to the field of Natural Language Processing (NLP). NLP is a branch of artificial intelligence that focuses on enabling machines to understand, interpret, and generate human-like language. As an integral part of the ongoing technological revolution, NLP has become crucial in bridging the communication gap between humans and machines.

% Why text is hard to understand for machines? 
Efforts to enable machines to understand written languages have been one of the major efforts of artificial intelligence research and development. 
The inherent ambiguity of language makes it difficult for machines to accurately interpret and comprehend text sentences which require context and nuanced understanding. 
Additionally, scientific texts in specialised domains often contain expert-level knowledge, technical terminology, conventions and specific abbreviations making it challenging for machines to process and comprehend such texts accurately. 
Finally, machines need to infer diacritics, understand the context, and interpret the meaning of the text accurately. 

% NLP / TDM introduction? 

Furthermore, Text Data Mining (TDM) plays a pivotal role in extracting valuable insights from vast amounts of textual data. In conjunction with machine learning algorithms, TDM empowers systems to not only understand the linguistic nuances of written text but also to derive meaningful patterns and knowledge from the information it processes.

This confluence of NLP and TDM, bolstered by advancements in machine learning, represents a key milestone in the evolution of technology. It not only addresses the challenges posed by the exponential growth of digital content but also opens up new possibilities for automating tasks, gaining deeper insights, and revolutionising how we interact with information in our everyday lives. In essence, the intersection of NLP and TDM with machine learning marks a transformative phase, reshaping the way we engage with the written word in the digital era.


% What is Machine learning? Discussion about different machine learning approaches, etc... 
Machine Learning (ML) is a transformative field within the realm of artificial intelligence (AI) that has garnered immense attention and applications in recent years. It is a powerful and interdisciplinary approach to computer science that enables computers to learn and make predictions or decisions without being explicitly programmed. In essence, it provides machines with the capability to recognise patterns, adapt to new data, and improve their performance over time, much like how humans learn from experience.
At its core, machine learning revolves around the idea of data-driven decision-making and  It relies on the analysis of large datasets to uncover hidden insights and relationships, which can then be used for tasks such as classification, regression, clustering, and recommendation. 
The way the model is built and used for learning includes supervised learning, unsupervised learning, and reinforcement learning, each tailored for different types of problems.
Supervised learning, perhaps the most common ML approach, involves training a model on a labelled dataset, where the algorithm learns to map input data to the correct output based on the provided labels. 
Unsupervised learning, on the other hand, deals with unlabelled data and seeks to discover inherent structures or patterns within the data. Reinforcement learning focuses on agents that interact with an environment, learning to make sequences of decisions that maximise a cumulative reward.

[TODO: add citations]
The applications of machine learning are myriad. In healthcare, ML is used for disease diagnosis, personalised treatment recommendations, and drug discovery. In finance, it aids in fraud detection, algorithmic trading, and credit scoring. ML has also transformed the way we interact with technology through virtual assistants like Siri and Alexa. Self-driving cars, powered by ML algorithms, are on the horizon, promising a revolution in transportation. Furthermore, ML is integral in natural language processing (NLP), enabling the development of chatbots, language translation services, and sentiment analysis.

With advancements in hardware, algorithms, and data availability, machine learning continues to evolve at a rapid pace. Deep learning, a subset of ML, employs artificial neural networks to achieve exceptional performance. 

% Computational science 
Building on the discussion about the transformative power of machine learning (ML), it's important to recognise that computational science and machine learning are closely intertwined. ML is a sub-field of computational science, and it often serves as the driving force behind many of its applications. The synergy between computational science and ML has opened new avenues for problem-solving and scientific discovery.
Computational science harnesses the capabilities of computers to create mathematical models and simulate complex systems, enabling researchers to gain insights and make predictions. Machine learning, on the other hand, equips computers with the ability to learn from data and make autonomous decisions. These two fields complement each other in profound ways, as computational science provides the infrastructure and methodologies to process vast datasets, while ML algorithms extract patterns and knowledge from this data.

The fusion of computational science and ML has ushered in a new era of data-driven discovery and problem-solving. Researchers now have the tools to analyse massive datasets, develop predictive models, and simulate complex phenomena with remarkable accuracy. For example, in computational biology, ML algorithms can analyse genetic data to identify disease markers and aid in personalised medicine. In environmental science, ML models can predict climate patterns and assess the impact of various interventions.
Moreover, the use of ML in computational science has the potential to automate tedious tasks, enabling scientists to focus on higher-level analysis and interpretation. For instance, image recognition algorithms can process large volumes of scientific images, identifying patterns or anomalies that might have gone unnoticed through manual inspection. This not only accelerates research but also enhances the robustness and reproducibility of results.

As the computational resources and algorithms continue to evolve, the collaboration between computational science and ML will lead to even more groundbreaking discoveries and innovations. It is a testament to the ever-expanding boundaries of human knowledge and technology, where the fusion of two powerful disciplines creates a force capable of solving some of the most complex challenges in science, engineering, and beyond.
