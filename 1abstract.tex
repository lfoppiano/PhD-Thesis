\begin{abstract}

The scientific literature, which contains vast human knowledge, is rapidly expanding, posing challenges in organising and retrieving information. 
The use of big data techniques aids in uncovering patterns and making predictions and has long been applied in chemistry and biology. 
While materials science has fallen behind, a new discipline called Materials Informatics (MI) has emerged in recent years, thanks to large collaborative projects such as the Material Project. 
MI is a discipline that leverages computational power to accelerate research in Materials Science by employing techniques like Density Functional Theory (DFT) computations and Machine Learning (ML). 
Despite advances, the limited availability of experimental datasets, such as SuperCon or the Pauling File, hinders progress. 
SuperCon is a database for superconductor materials constructed manually by Japan's National Institute for Materials Science (NIMS). 
NIMS faces challenges updating SuperCon manually due to high publication rates and scarcity of skilled labour force. 
Automated processes are needed to extract data from new publications promptly, and manual curation, which is prone to errors, requires careful tools and feature selection.

In this dissertation, we propose an end-to-end pipeline for extracting material information from the scientific literature to improve the efficiency and quality of material databases.
Our work aims to combine automated tasks and efficient tooling to reduce the dependency on human intelligence to the minimum. 
The automatic extraction pipeline processes scientific documents in PDF format and combines ML-based models for recognising complex material-related expressions.  
Material expressions are further processed by a specialised "Material parser" that decomposes granular information such as name, formulas, doping, shape, etc. 
The extraction of properties and conditions (e.g., 3K, 24 GPa, 12 atm) is performed by exploiting a general parser for extracting measurements of physical quantities: Grobid-quantities. 
Grobid-quantities support the identification and normalisation of measurements to the International System (SI) base units and allow the pipeline to support properties and conditions from various domains flexibly. 
Furthermore, to obtain the necessary high-quality training data for our ML-based processes, we developed SuperMat, a dataset of 164 superconductor articles for evaluation and training. Superconductor researchers constructed and validated the dataset and provided a structure containing annotated entities and relations.  
We demonstrate the efficacy of our pipeline by processing a large set of scientific articles from the Arixv repository and collecting a database with over 40000 extracted material-properties records. 
Finally, we proposed a curation workflow to validate the extracted data by combining an enhanced PDF viewer and a comprehensive interface. In general, using such a tool improved the quality of the extracted data with an increased precision by 6\% and recall by 47\% compared to the traditional manual approach of reading the plain PDF document and writing the data in an Excel file. 
The models, dataset, and interface developed in this work will help increase the automation and accuracy of the processing of materials databases such as SuperCon from the scientific literature.
\end{abstract}